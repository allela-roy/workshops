{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5eac386",
   "metadata": {},
   "source": [
    "### Text Similarity\n",
    "\n",
    "This notebook will lead you through:\n",
    "\n",
    "1. Downloading the Jina AI text embedding model `jina-embedding-t-en-v1` from HuggingFace using the built-in interface in Python.\n",
    "2. Input English-language texts to the AI model and retrieve embeddings for them\n",
    "3. Measure the cosines between embeddings to see that they match intuitions about text similarity.\n",
    "\n",
    "If you are running this notebook in an environment that may not have all the prerequisites installed, run the line below first. It will install the necessary libraries if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd5c67-a2fd-4ca2-ba7d-0bd1a95481ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy torch timm sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f4a34-f845-4259-9996-f9d55558fdf0",
   "metadata": {},
   "source": [
    "Import the `SentenceTransformer` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c21d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29028b92",
   "metadata": {},
   "source": [
    "Next, download the `jina-embedding-t-en-v1` and store it (along with its accompanying Python class) in the variable `model`. Be patient, this may take several minuites the first time you do it, but it will be cached on your local system for the next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54613e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('jinaai/jina-embedding-t-en-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32e3a5",
   "metadata": {},
   "source": [
    "You can get embeddings one at a time, using the `SentenceTransformer.encode()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf22c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_car = model.encode(\"This is a car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490e5e",
   "metadata": {},
   "source": [
    "Or you can get several embeddings at once by using batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22813285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This is a car\", \"This is a truck\", \"This is an airplane\", \"This is a dog\"]\n",
    "\n",
    "# The below is functionally equivalent, in Python, to:\n",
    "# embeddings_list = model.encode(sentences)\n",
    "# embedding_car = embeddings_list[0]\n",
    "# embedding_truck = embeddings_list[1]\n",
    "# embedding_airplane = embeddings_list[2]\n",
    "# embedding_dog = embeddings_list[3]\n",
    "\n",
    "embedding_car, embedding_truck, embedding_airplane, embedding_dog = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbfb359",
   "metadata": {},
   "source": [
    "You can see that each embedding has 312 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4fd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(embedding_car)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdaec6d",
   "metadata": {},
   "source": [
    "And if you inspect an embedding directly, you see it is just a vector -- a list of numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec34b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6632b0b",
   "metadata": {},
   "source": [
    "Define the cosine function over pairs of vectors, so we can compare embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cec3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(a, b):\n",
    "    return dot(a,b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b31f0f",
   "metadata": {},
   "source": [
    "Now, we can do pairwise comparisons between the embedding vectors. Remember, the closer the cosine is to 1.0, the more similar the two embeddings are.\n",
    "\n",
    "For example, `embedding_car` and `embedding_truck`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(embedding_car, embedding_truck)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b661270",
   "metadata": {},
   "source": [
    "This is a higher cosine than between `embedding_car` and `embedding_airplane`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12615fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(embedding_car, embedding_airplane)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f7b25",
   "metadata": {},
   "source": [
    "And much higher than between `embedding_car` and `embedding_dog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(embedding_car, embedding_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f9f97",
   "metadata": {},
   "source": [
    "Now, let’s create an additional embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_automobile = model.encode(\"This is an automobile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4aca4b",
   "metadata": {},
   "source": [
    "We would expect `embedding_car` and `embedding_automobile` to have nearly the same vector, since the two sentences mean more or less the same thing. This should be reflected in a very high cosine, one closer to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(embedding_car, embedding_automobile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29419ab",
   "metadata": {},
   "source": [
    "Try it with your own texts to see if the results match your intuitions about semantic similarity. \n",
    "\n",
    "The maximum input size to the `jina-embedding-t-en-v1` model is 512 tokens. This is not quite exactly 512 words because the tokenizer does not match tokens one-to-one with words, but that’s a good rough estimate. This is a relatively small model, so it has limitations in that respect.\n",
    "\n",
    "If you put in too much text, it will truncate it automatically to the maximum it accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506b043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
